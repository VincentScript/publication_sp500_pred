{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching S&P 500 (SPY ETF) data...\n",
      "Fetching Gold data...\n",
      "Fetching Treasury 3month data...\n",
      "Fetching Treasury 10year data...\n",
      "Data extraction complete. Files saved in the 'data' folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from datetime import datetime\n",
    "\n",
    "# Alpha Vantage API Key\n",
    "API_KEY = \"INSERT API KEY\"\n",
    "BASE_URL = \"https://www.alphavantage.co/query\"\n",
    "\n",
    "data_folder = \"data\"\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# Define the date range\n",
    "start_date = \"2022-01-01\"\n",
    "end_date = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Function to save DataFrame to CSV with timestamp column\n",
    "def save_df_to_csv(df, filename):\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df.sort_index()  # Ensure chronological order\n",
    "    df = df.loc[start_date:end_date]\n",
    "    df.index.name = \"timestamp\"\n",
    "    df.to_csv(os.path.join(data_folder, filename))\n",
    "\n",
    "# Fetch S&P 500 Data using SPY ETF as a proxy\n",
    "print(\"Fetching S&P 500 (SPY ETF) data...\")\n",
    "ts = TimeSeries(key=API_KEY, output_format='pandas')\n",
    "spy_data, _ = ts.get_daily(symbol=\"SPY\", outputsize=\"full\")\n",
    "spy_data.columns = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "save_df_to_csv(spy_data, \"sp500.csv\")\n",
    "\n",
    "# Fetch Gold Data using TIME_SERIES_DAILY\n",
    "print(\"Fetching Gold data...\")\n",
    "def fetch_gold_data():\n",
    "    params = {\n",
    "        \"function\": \"TIME_SERIES_DAILY\",\n",
    "        \"symbol\": \"GOLD\",\n",
    "        \"apikey\": API_KEY,\n",
    "        \"outputsize\": \"full\"\n",
    "    }\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    if \"Time Series (Daily)\" not in data:\n",
    "        print(\"Error fetching data:\", data)\n",
    "        return None\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame.from_dict(data[\"Time Series (Daily)\"], orient=\"index\")\n",
    "    df = df.rename(columns={\n",
    "        \"1. open\": \"Open\",\n",
    "        \"2. high\": \"High\",\n",
    "        \"3. low\": \"Low\",\n",
    "        \"4. close\": \"Close\",\n",
    "        \"5. volume\": \"Volume\"\n",
    "    })\n",
    "    \n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df.sort_index()\n",
    "    df.index.name = \"timestamp\"\n",
    "    return df\n",
    "\n",
    "gold_data = fetch_gold_data()\n",
    "if gold_data is not None:\n",
    "    save_df_to_csv(gold_data, \"gold.csv\")\n",
    "\n",
    "# Function to fetch Treasury yield data\n",
    "def fetch_treasury_yield(period, filename, column_name):\n",
    "    print(f\"Fetching Treasury {period} data...\")\n",
    "    url = f\"https://www.alphavantage.co/query?function=TREASURY_YIELD&interval=daily&maturity={period}&apikey={API_KEY}\"\n",
    "    response = requests.get(url).json()\n",
    "    if \"data\" in response:\n",
    "        treasury_data = {item['date']: item['value'] for item in response[\"data\"]}\n",
    "        df = pd.DataFrame.from_dict(treasury_data, orient='index', columns=[column_name])\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df = df.sort_index()  # Ensure chronological order\n",
    "        df = df.loc[start_date:end_date]\n",
    "        df.index.name = \"timestamp\"\n",
    "        df.to_csv(os.path.join(data_folder, filename))\n",
    "    else:\n",
    "        print(f\"Error fetching {period} treasury yield: {response}\")\n",
    "\n",
    "# Fetch Treasury 3-Month Data\n",
    "fetch_treasury_yield(\"3month\", \"treasury_3m.csv\", \"treasury_3m\")\n",
    "\n",
    "# Fetch Treasury 10-Year Data\n",
    "fetch_treasury_yield(\"10year\", \"treasury_10y.csv\", \"treasury_10y\")\n",
    "\n",
    "print(\"Data extraction complete. Files saved in the 'data' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Google Trends data...\n",
      "Google Trends data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pytrends.request import TrendReq\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define search keywords\n",
    "keywords = [\"sp500\", \"SPX\", \"index fund\", \"ETF\"]\n",
    "\n",
    "data_folder = \"data\"\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# Define the date range\n",
    "start_date = \"2022-01-01\"\n",
    "end_date = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Initialize Pytrends\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "# Function to fetch daily Google Trends data\n",
    "def fetch_google_trends():\n",
    "    print(\"Fetching Google Trends data...\")\n",
    "    pytrends.build_payload(kw_list=keywords, timeframe=f\"{start_date} {end_date}\", geo=\"US\")\n",
    "    trends_data = pytrends.interest_over_time()\n",
    "    \n",
    "    if trends_data.empty:\n",
    "        print(\"Error fetching Google Trends data: No data returned.\")\n",
    "        return None\n",
    "    \n",
    "    # Drop 'isPartial' column if it exists\n",
    "    trends_data = trends_data.drop(columns=['isPartial'], errors='ignore')\n",
    "    \n",
    "    # Resample to daily frequency if needed\n",
    "    trends_data = trends_data.resample('D').interpolate()\n",
    "    \n",
    "    # Format the DataFrame\n",
    "    trends_data.index.name = \"timestamp\"\n",
    "    trends_data = trends_data.sort_index()\n",
    "    return trends_data\n",
    "\n",
    "# Fetch data and save to CSV\n",
    "google_trends_data = fetch_google_trends()\n",
    "if google_trends_data is not None:\n",
    "    google_trends_data.to_csv(os.path.join(data_folder, \"google_trends.csv\"))\n",
    "    print(\"Google Trends data saved successfully.\")\n",
    "else:\n",
    "    print(\"Failed to fetch Google Trends data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Forex data for EUR/USD from Alpha Vantage...\n",
      "Fetching Forex data for USD/JPY from Alpha Vantage...\n",
      "Fetching Forex data for GBP/USD from Alpha Vantage...\n",
      "Fetching Forex data for AUD/USD from Alpha Vantage...\n",
      "Fetching Forex data for USD/CAD from Alpha Vantage...\n",
      "Forex data for top 5 pairs saved successfully as forex.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "# Alpha Vantage API Key\n",
    "API_KEY = \"INSERT API KEY\"\n",
    "\n",
    "# Define the data folder\n",
    "data_folder = \"data\"\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# List of top 5 most traded Forex pairs\n",
    "forex_pairs = [\n",
    "    (\"EUR\", \"USD\"),\n",
    "    (\"USD\", \"JPY\"),\n",
    "    (\"GBP\", \"USD\"),\n",
    "    (\"AUD\", \"USD\"),\n",
    "    (\"USD\", \"CAD\"),\n",
    "]\n",
    "\n",
    "# Define the date range\n",
    "start_date = \"2022-01-01\"\n",
    "end_date = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Function to fetch Forex data\n",
    "def fetch_forex_data(from_currency, to_currency):\n",
    "    print(f\"Fetching Forex data for {from_currency}/{to_currency} from Alpha Vantage...\")\n",
    "\n",
    "    url = f\"https://www.alphavantage.co/query?function=FX_DAILY&from_symbol={from_currency}&to_symbol={to_currency}&apikey={API_KEY}&outputsize=full\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching data for {from_currency}/{to_currency}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    data = response.json()\n",
    "    if \"Time Series FX (Daily)\" not in data:\n",
    "        print(f\"Error: {data.get('Error Message', 'No data returned.')} for {from_currency}/{to_currency}\")\n",
    "        return None\n",
    "\n",
    "    # Convert JSON data to DataFrame\n",
    "    df = pd.DataFrame.from_dict(data[\"Time Series FX (Daily)\"], orient=\"index\")\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # Rename columns with currency pair name\n",
    "    pair_name = f\"{from_currency}_{to_currency}\"\n",
    "    df.columns = [\"timestamp\", f\"open_{pair_name}\", f\"high_{pair_name}\", f\"low_{pair_name}\", f\"close_{pair_name}\"]\n",
    "\n",
    "    # Convert timestamp column\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "\n",
    "    # Filter by date range\n",
    "    df = df[(df[\"timestamp\"] >= start_date) & (df[\"timestamp\"] <= end_date)]\n",
    "\n",
    "    return df\n",
    "\n",
    "# Fetch data for all Forex pairs and merge into one DataFrame\n",
    "merged_df = None\n",
    "for from_currency, to_currency in forex_pairs:\n",
    "    forex_data = fetch_forex_data(from_currency, to_currency)\n",
    "    if forex_data is not None:\n",
    "        if merged_df is None:\n",
    "            merged_df = forex_data\n",
    "        else:\n",
    "            merged_df = pd.merge(merged_df, forex_data, on=\"timestamp\", how=\"outer\")\n",
    "\n",
    "# Save merged data to CSV\n",
    "if merged_df is not None:\n",
    "    merged_df.sort_values(\"timestamp\", inplace=True)\n",
    "    merged_df.to_csv(os.path.join(data_folder, \"forex.csv\"), index=False)\n",
    "    print(\"Forex data for top 5 pairs saved successfully as forex.csv.\")\n",
    "else:\n",
    "    print(\"Failed to fetch Forex data for any currency pair.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
