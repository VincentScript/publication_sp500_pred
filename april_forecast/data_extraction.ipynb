{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data/bitcoin.csv...\n",
      "‚úÖ Saved data/bitcoin.csv\n",
      "Processing data/copper.csv...\n",
      "‚úÖ Saved data/copper.csv\n",
      "Processing data/gold.csv...\n",
      "‚úÖ Saved data/gold.csv\n",
      "Processing data/sp500.csv...\n",
      "‚úÖ Saved data/sp500.csv\n",
      "Processing data/MOEX.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['IMOEX.ME']: YFPricesMissingError('possibly delisted; no price data found  (1d 2025-04-01 -> 2025-04-30)')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved data/MOEX.csv\n",
      "Processing data/SSE.csv...\n",
      "‚úÖ Saved data/SSE.csv\n",
      "Processing data/oil.csv...\n",
      "‚úÖ Saved data/oil.csv\n",
      "Processing data/google_trends.csv...\n",
      "‚ö†Ô∏è No ticker for google_trends.csv ‚Üí creating empty file.\n",
      "üéâ All datasets processed and saved.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "start_date = \"2025-04-01\"\n",
    "end_date = \"2025-04-30\"\n",
    "\n",
    "# Define each file with its ticker and required columns\n",
    "datasets = [\n",
    "    {\n",
    "        'filename': 'data/bitcoin.csv',\n",
    "        'ticker': 'BTC-USD',\n",
    "        'columns': ['timestamp', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    },\n",
    "    {\n",
    "        'filename': 'data/copper.csv',\n",
    "        'ticker': 'HG=F',\n",
    "        'columns': ['Price', 'copper_price']\n",
    "    },\n",
    "    {\n",
    "        'filename': 'data/gold.csv',\n",
    "        'ticker': 'GC=F',\n",
    "        'columns': ['timestamp', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    },\n",
    "    {\n",
    "        'filename': 'data/sp500.csv',\n",
    "        'ticker': '^GSPC',\n",
    "        'columns': ['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
    "    },\n",
    "    {\n",
    "        'filename': 'data/MOEX.csv',\n",
    "        'ticker': 'IMOEX.ME',\n",
    "        'columns': ['timestamp', 'Close', 'Open', 'High', 'Low']\n",
    "    },\n",
    "    {\n",
    "        'filename': 'data/SSE.csv',\n",
    "        'ticker': '000001.SS',\n",
    "        'columns': ['timestamp', 'Close', 'Open', 'High', 'Low']\n",
    "    },\n",
    "    {\n",
    "        'filename': 'data/oil.csv',\n",
    "        'ticker': 'CL=F',\n",
    "        'columns': ['timestamp', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    },\n",
    "    {\n",
    "        'filename': 'data/google_trends.csv',\n",
    "        'ticker': None,\n",
    "        'columns': ['timestamp', 'sp500', 'SPX', 'index fund', 'ETF']\n",
    "    }\n",
    "]\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset['filename']}...\")\n",
    "\n",
    "    if dataset['ticker']:\n",
    "        df = yf.download(dataset['ticker'], start=start_date, end=end_date)\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "        # Rename columns depending on the dataset\n",
    "        rename_dict = {'Date': 'timestamp'}\n",
    "        if dataset['filename'].endswith('sp500.csv'):\n",
    "            rename_dict.update({\n",
    "                'Open': 'open',\n",
    "                'High': 'high',\n",
    "                'Low': 'low',\n",
    "                'Close': 'close',\n",
    "                'Volume': 'volume'\n",
    "            })\n",
    "\n",
    "        df = df.rename(columns=rename_dict)\n",
    "\n",
    "        # Special handling for copper.csv\n",
    "        if dataset['filename'].endswith('copper.csv'):\n",
    "            df['Price'] = df['Close']\n",
    "            df['copper_price'] = df['Close']\n",
    "            df = df[dataset['columns']]\n",
    "\n",
    "        # Handling for MOEX or SSE\n",
    "        elif dataset['filename'].endswith('MOEX.csv') or dataset['filename'].endswith('SSE.csv'):\n",
    "            df = df[dataset['columns']]\n",
    "\n",
    "        # Default handling\n",
    "        else:\n",
    "            df = df[dataset['columns']]\n",
    "\n",
    "        df.to_csv(dataset['filename'], index=False)\n",
    "        print(f\"‚úÖ Saved {dataset['filename']}\")\n",
    "\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No ticker for google_trends.csv ‚Üí creating empty file.\")\n",
    "        df = pd.DataFrame(columns=dataset['columns'])\n",
    "        df.to_csv(dataset['filename'], index=False)\n",
    "\n",
    "print(\"üéâ All datasets processed and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing data/treasury_3m.csv...\n",
      "Original columns: ['timestamp', 'Close']\n",
      "Cleaned columns: ['timestamp', 'close']\n",
      "After renaming columns: ['timestamp', 'treasury3m']\n",
      "‚úÖ Saved data/treasury_3m.csv with corrected headers.\n",
      "Fixing data/treasury_10y.csv...\n",
      "Original columns: ['timestamp', 'Close']\n",
      "Cleaned columns: ['timestamp', 'close']\n",
      "After renaming columns: ['timestamp', 'treasury10y']\n",
      "‚úÖ Saved data/treasury_10y.csv with corrected headers.\n",
      "Fixing data/spgsci.csv...\n",
      "Original columns: ['date', 'open', 'high', 'low', 'close', 'volume']\n",
      "Cleaned columns: ['date', 'open', 'high', 'low', 'close', 'volume']\n",
      "After renaming columns: ['timestamp', 'open', 'high', 'low', 'Close', 'volume']\n",
      "‚úÖ Saved data/spgsci.csv with corrected headers.\n",
      "üéâ Header corrections complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "files_to_fix = [\n",
    "    {\n",
    "        'filename': 'data/treasury_3m.csv',\n",
    "        'rename_map': {'date': 'timestamp', 'close': 'treasury3m'},\n",
    "        'columns': ['timestamp', 'treasury3m']\n",
    "    },\n",
    "    {\n",
    "        'filename': 'data/treasury_10y.csv',\n",
    "        'rename_map': {'date': 'timestamp', 'close': 'treasury10y'},\n",
    "        'columns': ['timestamp', 'treasury10y']\n",
    "    },\n",
    "    {\n",
    "        'filename': 'data/spgsci.csv',\n",
    "        'rename_map': {'date': 'timestamp', 'close': 'Close'},\n",
    "        'columns': ['timestamp', 'Close']\n",
    "    }\n",
    "]\n",
    "\n",
    "for file in files_to_fix:\n",
    "    print(f\"Fixing {file['filename']}...\")\n",
    "\n",
    "    df = pd.read_csv(file['filename'], index_col=False)\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    \n",
    "    print(\"Original columns:\", df.columns.tolist())\n",
    "    \n",
    "    # Clean headers\n",
    "    df.columns = df.columns.str.strip().str.lower()  # lowercase everything for matching\n",
    "    print(\"Cleaned columns:\", df.columns.tolist())\n",
    "    \n",
    "    # Rename columns\n",
    "    df = df.rename(columns=file['rename_map'])\n",
    "    print(\"After renaming columns:\", df.columns.tolist())\n",
    "    \n",
    "    # Check for missing columns\n",
    "    missing_cols = [col for col in file['columns'] if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"‚ùå Missing columns: {missing_cols}\")\n",
    "        continue\n",
    "    \n",
    "    # Keep only the desired columns\n",
    "    df = df[file['columns']]\n",
    "    \n",
    "    # Save the cleaned CSV\n",
    "    df.to_csv(file['filename'], index=False)\n",
    "    print(f\"‚úÖ Saved {file['filename']} with corrected headers.\")\n",
    "\n",
    "print(\"üéâ Header corrections complete.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
